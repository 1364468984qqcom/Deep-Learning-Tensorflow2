{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 [==============================] - 1s 703us/step - loss: 0.0383 - accuracy: 0.7705 - val_loss: 0.0217 - val_accuracy: 0.8787\n",
      "Epoch 2/3\n",
      "1875/1875 [==============================] - 1s 685us/step - loss: 0.0203 - accuracy: 0.8812 - val_loss: 0.0177 - val_accuracy: 0.8963\n",
      "Epoch 3/3\n",
      "1875/1875 [==============================] - 1s 700us/step - loss: 0.0177 - accuracy: 0.8937 - val_loss: 0.0160 - val_accuracy: 0.9041\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = tf.keras.datasets.mnist\n",
    "# 载入数据，数据载入的时候就已经划分好训练集和测试集\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "# 把训练集和测试集的标签转为独热编码\n",
    "y_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\n",
    "\n",
    "# 模型定义\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28), name='flatten'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax', name='output')\n",
    "])\n",
    "\n",
    "# 定义优化器，代价函数\n",
    "sgd = SGD(0.2)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 传入训练集数据和标签训练模型\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=32, validation_data=(x_test,y_test))\n",
    "\n",
    "# 保存模型为SavedModel格式\n",
    "model.save('my_model/1')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['image_input'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 28, 28)\n",
      "        name: serving_default_image_input:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['output'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0523 17:08:42.953058 4320275904 deprecation.py:506] From /Users/qin/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          image_input: TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='image_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          image_input: TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='image_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          image_input: TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='image_input')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          image_input: TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='image_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          image_input: TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='image_input')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          inputs: TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='inputs')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "# 使用saved_model_cli命令查看path_to_saved_model文件夹中的信息\n",
    "!saved_model_cli show --dir my_model/ --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-d5d5f231354a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-d5d5f231354a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    signature_def['serving_default']:\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "signature_def['serving_default']:\n",
    "inputs['flatten_input']\n",
    "outputs['dense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-55-06d00840b9c9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-55-06d00840b9c9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    docker run -p {gRPC端口}:{gRPC端口} -p {REST API端口}:{REST API端口} --mount type=bind,source=$(pwd)/my_model,target=/models/my_model -e MODEL_NAME=my_model -t tensorflow/serving\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "docker run \\\n",
    "-p {gRPC}:{gRPC} \\\n",
    "-p {REST API}:{REST API} \\\n",
    "--mount type=bind,\\\n",
    "source={SavedModel_Path},\\\n",
    "target=/models/{Model_Name} \\\n",
    "-e MODEL_NAME={Model_Name} \\\n",
    "-t tensorflow/serving \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-23 09:28:22.280012: I tensorflow_serving/model_servers/server.cc:86] Building single TensorFlow model file config:  model_name: my_model model_base_path: /models/my_model\n",
      "2020-05-23 09:28:22.282301: I tensorflow_serving/model_servers/server_core.cc:462] Adding/updating models.\n",
      "2020-05-23 09:28:22.282356: I tensorflow_serving/model_servers/server_core.cc:573]  (Re-)adding model: my_model\n",
      "2020-05-23 09:28:22.404748: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: my_model version: 1}\n",
      "2020-05-23 09:28:22.404779: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: my_model version: 1}\n",
      "2020-05-23 09:28:22.404790: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: my_model version: 1}\n",
      "2020-05-23 09:28:22.405158: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /models/my_model/1\n",
      "2020-05-23 09:28:22.411158: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\n",
      "2020-05-23 09:28:22.411226: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:264] Reading SavedModel debug info (if present) from: /models/my_model/1\n",
      "2020-05-23 09:28:22.412710: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-05-23 09:28:22.462526: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:203] Restoring SavedModel bundle.\n",
      "2020-05-23 09:28:22.516705: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:152] Running initialization op on SavedModel bundle at path: /models/my_model/1\n",
      "2020-05-23 09:28:22.520230: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:333] SavedModel load for tags { serve }; Status: success: OK. Took 115061 microseconds.\n",
      "2020-05-23 09:28:22.521324: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /models/my_model/1/assets.extra/tf_serving_warmup_requests\n",
      "2020-05-23 09:28:22.535806: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: my_model version: 1}\n",
      "2020-05-23 09:28:22.540656: I tensorflow_serving/model_servers/server.cc:358] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
      "[warn] getaddrinfo: address family for nodename not supported\n",
      "2020-05-23 09:28:22.546679: I tensorflow_serving/model_servers/server.cc:378] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!docker run \\\n",
    "-p 8500:8500 \\\n",
    "-p 8501:8501 \\\n",
    "--mount type=bind,\\\n",
    "source=$(pwd)/my_model,\\\n",
    "target=/models/my_model \\\n",
    "-e MODEL_NAME=my_model \\\n",
    "-t tensorflow/serving \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-23 09:10:50.884630: I tensorflow_serving/model_servers/server.cc:86] Building single TensorFlow model file config:  model_name: my_model model_base_path: /models/my_model\n",
      "2020-05-23 09:10:50.887386: I tensorflow_serving/model_servers/server_core.cc:462] Adding/updating models.\n",
      "2020-05-23 09:10:50.887510: I tensorflow_serving/model_servers/server_core.cc:573]  (Re-)adding model: my_model\n",
      "2020-05-23 09:10:51.007926: I tensorflow_serving/core/basic_manager.cc:739] Successfully reserved resources to load servable {name: my_model version: 1}\n",
      "2020-05-23 09:10:51.007998: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: my_model version: 1}\n",
      "2020-05-23 09:10:51.008012: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: my_model version: 1}\n",
      "2020-05-23 09:10:51.008454: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: /models/my_model/1\n",
      "2020-05-23 09:10:51.016154: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\n",
      "2020-05-23 09:10:51.016223: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:264] Reading SavedModel debug info (if present) from: /models/my_model/1\n",
      "2020-05-23 09:10:51.017571: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-05-23 09:10:51.068698: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:203] Restoring SavedModel bundle.\n",
      "2020-05-23 09:10:51.126808: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:152] Running initialization op on SavedModel bundle at path: /models/my_model/1\n",
      "2020-05-23 09:10:51.130201: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:333] SavedModel load for tags { serve }; Status: success: OK. Took 121728 microseconds.\n",
      "2020-05-23 09:10:51.131015: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /models/my_model/1/assets.extra/tf_serving_warmup_requests\n",
      "2020-05-23 09:10:51.146442: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: my_model version: 1}\n",
      "2020-05-23 09:10:51.151423: I tensorflow_serving/model_servers/server.cc:358] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
      "[warn] getaddrinfo: address family for nodename not supported\n",
      "2020-05-23 09:10:51.161690: I tensorflow_serving/model_servers/server.cc:378] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!docker run -p 8500:8500 -p 8501:8501 --mount type=bind,source=$(pwd)/my_model,target=/models/my_model -e MODEL_NAME=my_model -t tensorflow/serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
