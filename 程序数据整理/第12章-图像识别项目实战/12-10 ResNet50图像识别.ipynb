{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input,Dense,Dropout,Conv2D,MaxPool2D,Flatten,GlobalAvgPool2D,concatenate,BatchNormalization,Activation,Add,ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别数\n",
    "num_classes = 17\n",
    "# 批次大小\n",
    "batch_size = 32\n",
    "# 周期数\n",
    "epochs = 100\n",
    "# 图片大小\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集数据进行数据增强\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range = 20,     # 随机旋转度数\n",
    "    width_shift_range = 0.1, # 随机水平平移\n",
    "    height_shift_range = 0.1,# 随机竖直平移\n",
    "    rescale = 1/255,         # 数据归一化\n",
    "    shear_range = 10,       # 随机错切变换\n",
    "    zoom_range = 0.1,        # 随机放大\n",
    "    horizontal_flip = True,  # 水平翻转\n",
    "    brightness_range=(0.7, 1.3), # 亮度变化\n",
    "    fill_mode = 'nearest',   # 填充方式\n",
    ") \n",
    "# 测试集数据只需要归一化就可以\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255,         # 数据归一化\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1088 images belonging to 17 classes.\n",
      "Found 272 images belonging to 17 classes.\n"
     ]
    }
   ],
   "source": [
    "# 训练集数据生成器，可以在训练时自动产生数据进行训练\n",
    "# 从'data/train'获得训练集数据\n",
    "# 获得数据后会把图片resize为image_size×image_size的大小\n",
    "# generator每次会产生batch_size个数据\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(image_size,image_size),\n",
    "    batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "# 测试集数据生成器\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'data/test',\n",
    "    target_size=(image_size,image_size),\n",
    "    batch_size=batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flower0': 0,\n",
       " 'flower1': 1,\n",
       " 'flower10': 2,\n",
       " 'flower11': 3,\n",
       " 'flower12': 4,\n",
       " 'flower13': 5,\n",
       " 'flower14': 6,\n",
       " 'flower15': 7,\n",
       " 'flower16': 8,\n",
       " 'flower2': 9,\n",
       " 'flower3': 10,\n",
       " 'flower4': 11,\n",
       " 'flower5': 12,\n",
       " 'flower6': 13,\n",
       " 'flower7': 14,\n",
       " 'flower8': 15,\n",
       " 'flower9': 16}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 字典的键为17个文件夹的名字，值为对应的分类编号\n",
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 112, 112, 64) 9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 112, 112, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 56, 56, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 56, 56, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 56, 56, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 56, 56, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 56, 56, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 56, 56, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 56, 56, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 56, 56, 256)  0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 56, 56, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 56, 56, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 56, 56, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           batch_normalization_7[0][0]      \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 56, 56, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 56, 56, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 56, 56, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 56, 56, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 56, 56, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 56, 56, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           batch_normalization_10[0][0]     \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 28, 28, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 28, 28, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 512)  0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           batch_normalization_17[0][0]     \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 28, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 28, 28, 512)  2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_20[0][0]     \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 28, 28, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 28, 28, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 28, 28, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 28, 28, 512)  2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_23[0][0]     \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 14, 14, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 14, 14, 256)  1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 14, 14, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 14, 14, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 14, 14, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 14, 14, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 14, 14, 1024) 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 14, 14, 1024) 4096        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 14, 14, 1024) 4096        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_27[0][0]     \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 14, 14, 256)  262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 14, 14, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 14, 14, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 14, 14, 1024) 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 14, 14, 1024) 4096        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_30[0][0]     \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 256)  262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 14, 14, 256)  1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 256)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 14, 14, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 14, 14, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 14, 14, 1024) 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 14, 14, 1024) 4096        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_33[0][0]     \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 256)  262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 14, 14, 256)  1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 256)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 14, 14, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 14, 14, 256)  1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 1024) 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 14, 14, 1024) 4096        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_36[0][0]     \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 256)  262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 14, 14, 256)  1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 256)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 14, 14, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 14, 14, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 1024) 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 14, 14, 1024) 4096        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_39[0][0]     \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 256)  262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 256)  1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 256)  1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 1024) 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 1024) 4096        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_42[0][0]     \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 512)    524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 512)    2048        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 512)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 512)    2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 512)    2048        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 2048)   2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 2048)   8192        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 2048)   8192        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_46[0][0]     \n",
      "                                                                 batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 512)    1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 512)    2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 512)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 512)    2048        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 2048)   8192        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_49[0][0]     \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 512)    2048        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 512)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 512)    2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 2048)   8192        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_52[0][0]     \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 17)           34833       global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 23,622,545\n",
      "Trainable params: 23,569,425\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 定义残差单元\n",
    "def block(x, filters, strides=1, conv_shortcut=True): \n",
    "    # projection shortcut\n",
    "    if conv_shortcut == True:\n",
    "        shortcut = Conv2D(filters*4,kernel_size=1,strides=strides,padding='valid')(x)\n",
    "        # epsilon为BN公式中防止分母为零的值\n",
    "        shortcut = BatchNormalization(epsilon=1.001e-5)(shortcut)\n",
    "    else:\n",
    "        # identity_shortcut\n",
    "        shortcut = x\n",
    "    # 3个卷积层\n",
    "    x = Conv2D(filters=filters,kernel_size=1,strides=strides,padding='valid')(x)\n",
    "    x = BatchNormalization(epsilon=1.001e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    " \n",
    "    x = Conv2D(filters=filters,kernel_size=3,strides=1,padding='same')(x)\n",
    "    x = BatchNormalization(epsilon=1.001e-5)(x)\n",
    "    x = Activation('relu')(x)\n",
    " \n",
    "    x = Conv2D(filters=filters*4,kernel_size=1,strides=1,padding='valid')(x)\n",
    "    x = BatchNormalization(epsilon=1.001e-5)(x)\n",
    " \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# 堆叠残差单元\n",
    "def stack(x, filters, blocks, strides):\n",
    "    x = block(x, filters, strides=strides)\n",
    "    for i in range(blocks-1):\n",
    "        x = block(x, filters, conv_shortcut=False)\n",
    "    return x\n",
    "    \n",
    "# 定义ResNet50\n",
    "inputs = Input(shape=(image_size,image_size,3))\n",
    "# 填充3圈0，填充后图像从224×224变成230×230\n",
    "x = ZeroPadding2D((3, 3))(inputs)\n",
    "x= Conv2D(filters=64,kernel_size=7,strides=2,padding='valid')(x)\n",
    "x = BatchNormalization(epsilon=1.001e-5)(x)\n",
    "x = Activation('relu')(x)\n",
    "# 填充1圈0\n",
    "x = ZeroPadding2D((1, 1))(x)\n",
    "x = MaxPool2D(pool_size=3,strides=2,padding='valid')(x)\n",
    "# 堆叠残差结构\n",
    "# blocks表示堆叠数量\n",
    "x = stack(x, filters=64, blocks=3, strides=1)\n",
    "x = stack(x, filters=128, blocks=4, strides=2)\n",
    "x = stack(x, filters=256, blocks=6, strides=2)\n",
    "x = stack(x, filters=512, blocks=3, strides=2)\n",
    "# 根据特征图大小进行平均池化，池化后得到2维数据\n",
    "x = GlobalAvgPool2D()(x)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "# 定义模型\n",
    "model = Model(inputs=inputs,outputs=x)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习率调节函数，逐渐减小学习率\n",
    "def adjust_learning_rate(epoch):\n",
    "    # 前40周期\n",
    "    if epoch<=40:\n",
    "        lr = 1e-4\n",
    "    # 前40到80周期\n",
    "    elif epoch>40 and epoch<=80:\n",
    "        lr = 1e-5\n",
    "    # 80到100周期\n",
    "    else:\n",
    "        lr = 1e-6\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0317 20:41:17.333772 11892 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "W0317 20:41:17.475393 11892 data_adapter.py:1091] sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 34 steps, validate for 9 steps\n",
      "Epoch 1/100\n",
      "34/34 [==============================] - 19s 546ms/step - loss: 3.0563 - accuracy: 0.1195 - val_loss: 2.8569 - val_accuracy: 0.0588\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 14s 399ms/step - loss: 2.4523 - accuracy: 0.2022 - val_loss: 2.9909 - val_accuracy: 0.0588\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 14s 404ms/step - loss: 2.2453 - accuracy: 0.2564 - val_loss: 3.3687 - val_accuracy: 0.0588\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 14s 400ms/step - loss: 1.9453 - accuracy: 0.3438 - val_loss: 3.6266 - val_accuracy: 0.0588\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 14s 400ms/step - loss: 1.8935 - accuracy: 0.3851 - val_loss: 3.7225 - val_accuracy: 0.0588\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 14s 400ms/step - loss: 1.7313 - accuracy: 0.4449 - val_loss: 4.5830 - val_accuracy: 0.0588\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 14s 400ms/step - loss: 1.6125 - accuracy: 0.4642 - val_loss: 3.9271 - val_accuracy: 0.0699\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 14s 400ms/step - loss: 1.4799 - accuracy: 0.4908 - val_loss: 4.2458 - val_accuracy: 0.0625\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 14s 408ms/step - loss: 1.3685 - accuracy: 0.5358 - val_loss: 4.5996 - val_accuracy: 0.0662\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 14s 399ms/step - loss: 1.3043 - accuracy: 0.5561 - val_loss: 4.1217 - val_accuracy: 0.1176\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 1.2192 - accuracy: 0.5965 - val_loss: 3.0447 - val_accuracy: 0.2426\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 13s 396ms/step - loss: 1.1794 - accuracy: 0.6011 - val_loss: 3.2363 - val_accuracy: 0.2169\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 13s 396ms/step - loss: 1.0225 - accuracy: 0.6517 - val_loss: 3.1620 - val_accuracy: 0.1985\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 1.0204 - accuracy: 0.6599 - val_loss: 2.4032 - val_accuracy: 0.2941\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 1.0049 - accuracy: 0.6719 - val_loss: 1.9223 - val_accuracy: 0.4449\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.9260 - accuracy: 0.6939 - val_loss: 1.7231 - val_accuracy: 0.5037\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.8098 - accuracy: 0.7096 - val_loss: 1.5238 - val_accuracy: 0.5809\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.8171 - accuracy: 0.7151 - val_loss: 1.2644 - val_accuracy: 0.6029\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.7303 - accuracy: 0.7555 - val_loss: 1.2005 - val_accuracy: 0.6544\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.6983 - accuracy: 0.7601 - val_loss: 1.6134 - val_accuracy: 0.6140\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 13s 396ms/step - loss: 0.6147 - accuracy: 0.7895 - val_loss: 1.4561 - val_accuracy: 0.6434\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.5857 - accuracy: 0.7996 - val_loss: 1.4748 - val_accuracy: 0.6066\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.5061 - accuracy: 0.8244 - val_loss: 1.5286 - val_accuracy: 0.6434\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.5444 - accuracy: 0.8199 - val_loss: 1.7453 - val_accuracy: 0.6507\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.4941 - accuracy: 0.8143 - val_loss: 1.6600 - val_accuracy: 0.6140\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 13s 396ms/step - loss: 0.4996 - accuracy: 0.8336 - val_loss: 2.0659 - val_accuracy: 0.5221\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.3961 - accuracy: 0.8667 - val_loss: 1.8122 - val_accuracy: 0.5772\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 14s 399ms/step - loss: 0.3682 - accuracy: 0.8842 - val_loss: 1.6807 - val_accuracy: 0.6213\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 14s 408ms/step - loss: 0.3322 - accuracy: 0.8833 - val_loss: 1.8392 - val_accuracy: 0.6176\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 14s 409ms/step - loss: 0.3007 - accuracy: 0.8980 - val_loss: 1.1980 - val_accuracy: 0.6765\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 14s 405ms/step - loss: 0.2860 - accuracy: 0.9072 - val_loss: 1.7768 - val_accuracy: 0.6066\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 14s 405ms/step - loss: 0.3304 - accuracy: 0.8824 - val_loss: 1.3238 - val_accuracy: 0.7169\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 14s 405ms/step - loss: 0.3651 - accuracy: 0.8612 - val_loss: 2.7510 - val_accuracy: 0.5074\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 14s 398ms/step - loss: 0.3199 - accuracy: 0.8934 - val_loss: 1.3901 - val_accuracy: 0.6544\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.2930 - accuracy: 0.9035 - val_loss: 1.6742 - val_accuracy: 0.6324\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.3316 - accuracy: 0.8888 - val_loss: 1.3966 - val_accuracy: 0.6912\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 13s 396ms/step - loss: 0.2470 - accuracy: 0.9154 - val_loss: 1.3374 - val_accuracy: 0.7243\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.2124 - accuracy: 0.9338 - val_loss: 1.1744 - val_accuracy: 0.7243\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 14s 397ms/step - loss: 0.1859 - accuracy: 0.9403 - val_loss: 1.7454 - val_accuracy: 0.6434\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.1565 - accuracy: 0.9485 - val_loss: 1.4114 - val_accuracy: 0.7132\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.1986 - accuracy: 0.9265 - val_loss: 1.5670 - val_accuracy: 0.6397\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.1235 - accuracy: 0.9596 - val_loss: 1.1035 - val_accuracy: 0.7279\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0814 - accuracy: 0.9779 - val_loss: 1.0458 - val_accuracy: 0.7426\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0736 - accuracy: 0.9825 - val_loss: 0.9447 - val_accuracy: 0.7647\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 14s 399ms/step - loss: 0.0599 - accuracy: 0.9899 - val_loss: 0.9003 - val_accuracy: 0.7978\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 14s 397ms/step - loss: 0.0649 - accuracy: 0.9835 - val_loss: 0.8965 - val_accuracy: 0.7868\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0489 - accuracy: 0.9908 - val_loss: 0.8833 - val_accuracy: 0.7941\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 13s 396ms/step - loss: 0.0570 - accuracy: 0.9890 - val_loss: 0.9005 - val_accuracy: 0.7831\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.0449 - accuracy: 0.9917 - val_loss: 0.9214 - val_accuracy: 0.7684\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0458 - accuracy: 0.9926 - val_loss: 0.9146 - val_accuracy: 0.7831\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0415 - accuracy: 0.9936 - val_loss: 0.9124 - val_accuracy: 0.7794\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.9126 - val_accuracy: 0.7757\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0401 - accuracy: 0.9936 - val_loss: 0.9014 - val_accuracy: 0.7794\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.0407 - accuracy: 0.9926 - val_loss: 0.9065 - val_accuracy: 0.7721\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0464 - accuracy: 0.9908 - val_loss: 0.9103 - val_accuracy: 0.7721\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.0376 - accuracy: 0.9954 - val_loss: 0.9372 - val_accuracy: 0.7684\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.0343 - accuracy: 0.9963 - val_loss: 0.9366 - val_accuracy: 0.7684\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.0316 - accuracy: 0.9926 - val_loss: 0.9459 - val_accuracy: 0.7794\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.0395 - accuracy: 0.9936 - val_loss: 0.9200 - val_accuracy: 0.7757\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0369 - accuracy: 0.9926 - val_loss: 0.9239 - val_accuracy: 0.7794\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0308 - accuracy: 0.9963 - val_loss: 0.9130 - val_accuracy: 0.7831\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.0312 - accuracy: 0.9972 - val_loss: 0.9587 - val_accuracy: 0.7610\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0373 - accuracy: 0.9917 - val_loss: 0.9695 - val_accuracy: 0.7684\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 14s 407ms/step - loss: 0.0322 - accuracy: 0.9963 - val_loss: 0.9435 - val_accuracy: 0.7757\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 14s 406ms/step - loss: 0.0282 - accuracy: 0.9963 - val_loss: 0.9501 - val_accuracy: 0.7794\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 14s 405ms/step - loss: 0.0281 - accuracy: 0.9963 - val_loss: 0.9427 - val_accuracy: 0.7610\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 14s 405ms/step - loss: 0.0303 - accuracy: 0.9972 - val_loss: 0.9490 - val_accuracy: 0.7647\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 14s 403ms/step - loss: 0.0297 - accuracy: 0.9954 - val_loss: 1.0019 - val_accuracy: 0.7721\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 14s 399ms/step - loss: 0.0266 - accuracy: 0.9936 - val_loss: 0.9448 - val_accuracy: 0.7794\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0235 - accuracy: 0.9982 - val_loss: 0.9463 - val_accuracy: 0.7831\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0253 - accuracy: 0.9963 - val_loss: 0.9607 - val_accuracy: 0.7794\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0287 - accuracy: 0.9945 - val_loss: 0.9934 - val_accuracy: 0.7684\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.0246 - accuracy: 0.9963 - val_loss: 0.9847 - val_accuracy: 0.7757\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 13s 396ms/step - loss: 0.0284 - accuracy: 0.9954 - val_loss: 0.9835 - val_accuracy: 0.7647\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0258 - accuracy: 0.9963 - val_loss: 0.9876 - val_accuracy: 0.7721\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 14s 397ms/step - loss: 0.0348 - accuracy: 0.9917 - val_loss: 0.9849 - val_accuracy: 0.7684\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0243 - accuracy: 0.9963 - val_loss: 0.9803 - val_accuracy: 0.7831\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.0219 - accuracy: 0.9982 - val_loss: 0.9645 - val_accuracy: 0.7831\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 14s 397ms/step - loss: 0.0236 - accuracy: 0.9954 - val_loss: 1.0292 - val_accuracy: 0.7794\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.9872 - val_accuracy: 0.7904\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 13s 393ms/step - loss: 0.0199 - accuracy: 0.9972 - val_loss: 0.9985 - val_accuracy: 0.7831\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.0264 - accuracy: 0.9945 - val_loss: 1.0014 - val_accuracy: 0.7868\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0237 - accuracy: 0.9963 - val_loss: 1.0009 - val_accuracy: 0.7831\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.0186 - accuracy: 0.9972 - val_loss: 1.0043 - val_accuracy: 0.7794\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 13s 394ms/step - loss: 0.0190 - accuracy: 0.9982 - val_loss: 1.0093 - val_accuracy: 0.7757\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 13s 395ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 1.0107 - val_accuracy: 0.7794\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 14s 403ms/step - loss: 0.0200 - accuracy: 0.9982 - val_loss: 1.0081 - val_accuracy: 0.7721\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 14s 406ms/step - loss: 0.0204 - accuracy: 0.9972 - val_loss: 1.0078 - val_accuracy: 0.7794\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 14s 406ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.0084 - val_accuracy: 0.7757\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 14s 406ms/step - loss: 0.0201 - accuracy: 0.9954 - val_loss: 1.0135 - val_accuracy: 0.7757\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 14s 405ms/step - loss: 0.0216 - accuracy: 0.9945 - val_loss: 1.0145 - val_accuracy: 0.7721\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 14s 407ms/step - loss: 0.0170 - accuracy: 0.9982 - val_loss: 1.0114 - val_accuracy: 0.7721\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 14s 404ms/step - loss: 0.0193 - accuracy: 0.9982 - val_loss: 1.0073 - val_accuracy: 0.7684\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 14s 404ms/step - loss: 0.0193 - accuracy: 0.9972 - val_loss: 1.0111 - val_accuracy: 0.7684\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 14s 404ms/step - loss: 0.0225 - accuracy: 0.9954 - val_loss: 1.0096 - val_accuracy: 0.7721\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 14s 404ms/step - loss: 0.0192 - accuracy: 0.9972 - val_loss: 1.0097 - val_accuracy: 0.7757\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 14s 404ms/step - loss: 0.0201 - accuracy: 0.9982 - val_loss: 1.0064 - val_accuracy: 0.7757\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 14s 404ms/step - loss: 0.0196 - accuracy: 0.9963 - val_loss: 1.0084 - val_accuracy: 0.7757\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 14s 406ms/step - loss: 0.0224 - accuracy: 0.9954 - val_loss: 1.0080 - val_accuracy: 0.7794\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 14s 404ms/step - loss: 0.0229 - accuracy: 0.9972 - val_loss: 1.0078 - val_accuracy: 0.7794\n"
     ]
    }
   ],
   "source": [
    "# 定义优化器\n",
    "adam = Adam(lr=1e-4)\n",
    "\n",
    "# 定义学习率衰减策略\n",
    "callbacks = []\n",
    "callbacks.append(LearningRateScheduler(adjust_learning_rate))\n",
    "\n",
    "# 定义优化器，loss function，训练过程中计算准确率\n",
    "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Tensorflow2.1版本之前可以使用fit_generator训练模型\n",
    "# history = model.fit_generator(train_generator,steps_per_epoch=len(train_generator),epochs=epochs,validation_data=test_generator,validation_steps=len(test_generator))\n",
    "\n",
    "# Tensorflow2.1版本(包括2.1)之后可以直接使用fit训练模型\n",
    "history = model.fit(x=train_generator,epochs=epochs,validation_data=test_generator,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20ca293ff98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画出训练集准确率曲线图\n",
    "plt.plot(np.arange(epochs),history.history['accuracy'],c='b',label='train_accuracy')\n",
    "# 画出验证集准确率曲线图\n",
    "plt.plot(np.arange(epochs),history.history['val_accuracy'],c='y',label='val_accuracy')\n",
    "# 图例\n",
    "plt.legend()\n",
    "# x坐标描述\n",
    "plt.xlabel('epochs')\n",
    "# y坐标描述\n",
    "plt.ylabel('accuracy')\n",
    "# 显示图像\n",
    "plt.show()\n",
    "# 模型保存\n",
    "model.save('ResNet50.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
