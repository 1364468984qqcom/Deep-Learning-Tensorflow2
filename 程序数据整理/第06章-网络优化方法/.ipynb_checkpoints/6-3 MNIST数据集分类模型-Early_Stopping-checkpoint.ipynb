{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0267 - accuracy: 0.8420 - val_loss: 0.0167 - val_accuracy: 0.8999\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0164 - accuracy: 0.8993 - val_loss: 0.0145 - val_accuracy: 0.9095\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.0149 - accuracy: 0.9074 - val_loss: 0.0136 - val_accuracy: 0.9145\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0141 - accuracy: 0.9115 - val_loss: 0.0131 - val_accuracy: 0.9180\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0135 - accuracy: 0.9146 - val_loss: 0.0128 - val_accuracy: 0.9180\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0131 - accuracy: 0.9174 - val_loss: 0.0125 - val_accuracy: 0.9203\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0128 - accuracy: 0.9192 - val_loss: 0.0123 - val_accuracy: 0.9209\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.0126 - accuracy: 0.9204 - val_loss: 0.0122 - val_accuracy: 0.9209\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0124 - accuracy: 0.9215 - val_loss: 0.0119 - val_accuracy: 0.9230\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0122 - accuracy: 0.9230 - val_loss: 0.0119 - val_accuracy: 0.9237\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.0121 - accuracy: 0.9240 - val_loss: 0.0118 - val_accuracy: 0.9234\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0119 - accuracy: 0.9253 - val_loss: 0.0117 - val_accuracy: 0.9249\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 33us/sample - loss: 0.0118 - accuracy: 0.9257 - val_loss: 0.0116 - val_accuracy: 0.9264\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 32us/sample - loss: 0.0117 - accuracy: 0.9264 - val_loss: 0.0116 - val_accuracy: 0.9258\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.0116 - accuracy: 0.9276 - val_loss: 0.0115 - val_accuracy: 0.9270\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0115 - accuracy: 0.9279 - val_loss: 0.0115 - val_accuracy: 0.9262\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0115 - accuracy: 0.9286 - val_loss: 0.0114 - val_accuracy: 0.9265\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0114 - accuracy: 0.9289 - val_loss: 0.0115 - val_accuracy: 0.9264\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0113 - accuracy: 0.9293 - val_loss: 0.0115 - val_accuracy: 0.9272\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0113 - accuracy: 0.9298 - val_loss: 0.0115 - val_accuracy: 0.9264\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0112 - accuracy: 0.9301 - val_loss: 0.0113 - val_accuracy: 0.9264\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.0112 - accuracy: 0.9302 - val_loss: 0.0113 - val_accuracy: 0.9278\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0111 - accuracy: 0.9308 - val_loss: 0.0112 - val_accuracy: 0.9289\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0110 - accuracy: 0.9309 - val_loss: 0.0113 - val_accuracy: 0.9283\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0110 - accuracy: 0.9316 - val_loss: 0.0112 - val_accuracy: 0.9290\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.0110 - accuracy: 0.9316 - val_loss: 0.0112 - val_accuracy: 0.9279\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0109 - accuracy: 0.9321 - val_loss: 0.0112 - val_accuracy: 0.9286\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0109 - accuracy: 0.9325 - val_loss: 0.0111 - val_accuracy: 0.9293\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0108 - accuracy: 0.9328 - val_loss: 0.0111 - val_accuracy: 0.9292\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0108 - accuracy: 0.9329 - val_loss: 0.0111 - val_accuracy: 0.9293\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.0108 - accuracy: 0.9330 - val_loss: 0.0111 - val_accuracy: 0.9299\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0107 - accuracy: 0.9332 - val_loss: 0.0110 - val_accuracy: 0.9295\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0107 - accuracy: 0.9339 - val_loss: 0.0110 - val_accuracy: 0.9299\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0107 - accuracy: 0.9344 - val_loss: 0.0110 - val_accuracy: 0.9296\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0106 - accuracy: 0.9339 - val_loss: 0.0110 - val_accuracy: 0.9286\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0106 - accuracy: 0.9347 - val_loss: 0.0110 - val_accuracy: 0.9299\n",
      "Epoch 00036: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb3167b048>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = tf.keras.datasets.mnist\n",
    "# 载入数据，数据载入的时候就已经划分好训练集和测试集\n",
    "# 训练集数据x_train的数据形状为（60000，28，28）\n",
    "# 训练集标签y_train的数据形状为（60000）\n",
    "# 测试集数据x_test的数据形状为（10000，28，28）\n",
    "# 测试集标签y_test的数据形状为（10000）\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# 对训练集和测试集的数据进行归一化处理，有助于提升模型训练速度\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "# 把训练集和测试集的标签转为独热编码\n",
    "y_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\n",
    "\n",
    "# 模型定义\n",
    "# 先用Flatten把数据从3维变成2维，(60000,28,28)->(60000,784)\n",
    "# 设置输入数据形状input_shape不需要包含数据的数量，（28,28）即可\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# sgd定义随机梯度下降法优化器\n",
    "# loss='mse'定义均方差代价函数\n",
    "# metrics=['accuracy']模型在训练的过程中同时计算准确率\n",
    "sgd = SGD(0.5)\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# EarlyStopping是Callbacks的一种，callbacks用于指定在每个epoch或batch开始和结束的时候进行哪种特定操作\n",
    "# monitor='val_accuracy',监控验证集准确率\n",
    "# patience=5,连续5个周期没有超过最高的val_accuracy值，则提前停止训练\n",
    "# verbose=1，停止训练时提示early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
    "\n",
    "# 传入训练集数据和标签训练模型\n",
    "# 周期大小为100（把所有训练集数据训练一次称为训练一个周期）\n",
    "# 批次大小为32（每次训练模型传入32个数据进行训练）\n",
    "# validation_data设置验证集数据\n",
    "# callbacks=[early_stopping]设置early_stopping\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=100, \n",
    "          batch_size=32,  \n",
    "          validation_data=(x_test,y_test),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
